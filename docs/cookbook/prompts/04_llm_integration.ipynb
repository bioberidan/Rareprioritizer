{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Complete LLM Integration Examples\n",
        "\n",
        "This notebook provides complete, working examples of integrating the prompt system with various LLM providers.\n",
        "\n",
        "## Overview\n",
        "\n",
        "We'll cover:\n",
        "- ü§ñ **OpenAI Integration**: Chat completions with structured JSON\n",
        "- üß† **Anthropic Integration**: Claude with response validation  \n",
        "- ‚ö° **Error Handling**: Robust error management patterns\n",
        "- üîÑ **Response Processing**: Parsing and validation workflows\n",
        "- üìä **Real Examples**: Working code with actual disease analysis\n",
        "\n",
        "**Note**: This notebook includes mock examples that you can adapt with your actual API keys.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import json\n",
        "import os\n",
        "from typing import Dict, Any\n",
        "\n",
        "# Initialize prompt system\n",
        "import apps.research_prioritization.prompts.prompt_registry\n",
        "from utils.prompts import Prompter, PromptNotFoundError\n",
        "from pydantic import ValidationError\n",
        "\n",
        "# Mock LLM responses for demonstration\n",
        "MOCK_RESPONSES = {\n",
        "    \"socioeconomic\": {\n",
        "        \"orphacode\": \"905\",\n",
        "        \"disease_name\": \"Wilson disease\",\n",
        "        \"socioeconomic_impact_studies\": [\n",
        "            {\n",
        "                \"cost\": 25000,\n",
        "                \"measure\": \"Annual healthcare costs\",\n",
        "                \"label\": \"Economic burden of Wilson disease in Spain\",\n",
        "                \"source\": \"https://pubmed.ncbi.nlm.nih.gov/12345678\",\n",
        "                \"country\": \"Spain\",\n",
        "                \"year\": \"2023\"\n",
        "            }\n",
        "        ],\n",
        "        \"score\": 7,\n",
        "        \"evidence_level\": \"Medium-High evidence\",\n",
        "        \"justification\": \"Based on peer-reviewed Spanish cost-of-illness study with comprehensive healthcare cost analysis.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"üöÄ Setup complete!\")\n",
        "prompter = Prompter()\n",
        "print(f\"üìã Available prompts: {prompter.list_prompts()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Complete integration function (with mock LLM for demo)\n",
        "def analyze_disease_with_prompts(\n",
        "    disease_name: str, \n",
        "    orphacode: str, \n",
        "    prompt_type: str = \"socioeconomic\",\n",
        "    version: str = \"v1\",\n",
        "    use_mock: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Complete disease analysis using the prompt system.\n",
        "    \n",
        "    Args:\n",
        "        disease_name: Name of the disease\n",
        "        orphacode: ORPHA code  \n",
        "        prompt_type: Type of analysis (socioeconomic, groups)\n",
        "        version: Prompt version (v1, v2)\n",
        "        use_mock: Use mock response for demo (True) or real LLM (False)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Get the prompt\n",
        "        prompt_alias = f\"{prompt_type}_{version}\"\n",
        "        prompt = prompter.get_prompt(prompt_alias)\n",
        "        print(f\"‚úÖ Got prompt: {prompt_alias}\")\n",
        "        \n",
        "        # 2. Format template\n",
        "        template = prompt.template.format(\n",
        "            disease_name=disease_name,\n",
        "            orphacode=orphacode\n",
        "        )\n",
        "        print(f\"üìù Template formatted ({len(template)} chars)\")\n",
        "        \n",
        "        # 3. Call LLM (mock or real)\n",
        "        if use_mock:\n",
        "            # Use mock response for demonstration\n",
        "            llm_response = json.dumps(MOCK_RESPONSES[prompt_type])\n",
        "            print(\"üé≠ Using mock LLM response\")\n",
        "        else:\n",
        "            # This is where you'd call your actual LLM\n",
        "            # llm_response = your_llm_call(template)\n",
        "            llm_response = json.dumps(MOCK_RESPONSES[prompt_type])\n",
        "            print(\"ü§ñ Would call real LLM here\")\n",
        "            \n",
        "        # 4. Parse response\n",
        "        parsed_response = prompt.parser(llm_response)\n",
        "        print(\"üîÑ Response parsed\")\n",
        "        \n",
        "        # 5. Validate with Pydantic\n",
        "        validated_data = prompt.model(**json.loads(parsed_response))\n",
        "        print(\"‚úÖ Data validated successfully!\")\n",
        "        \n",
        "        return validated_data\n",
        "        \n",
        "    except PromptNotFoundError as e:\n",
        "        print(f\"‚ùå Prompt not found: {prompt_alias}\")\n",
        "        print(f\"üìã Available: {e.available_prompts}\")\n",
        "        raise\n",
        "        \n",
        "    except ValidationError as e:\n",
        "        print(f\"‚ùå Validation failed:\")\n",
        "        for error in e.errors():\n",
        "            print(f\"   ‚Ä¢ {error['loc']}: {error['msg']}\")\n",
        "        raise\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unexpected error: {e}\")\n",
        "        raise\n",
        "\n",
        "# Test the function\n",
        "result = analyze_disease_with_prompts(\n",
        "    disease_name=\"Wilson disease\",\n",
        "    orphacode=\"905\", \n",
        "    prompt_type=\"socioeconomic\",\n",
        "    version=\"v1\"\n",
        ")\n",
        "\n",
        "print(f\"\\nüéØ Analysis Result:\")\n",
        "print(f\"   Disease: {result.disease_name} ({result.orphacode})\")\n",
        "print(f\"   Score: {result.score}\")\n",
        "print(f\"   Evidence: {result.evidence_level}\")\n",
        "print(f\"   Studies found: {len(result.socioeconomic_impact_studies)}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
