{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Monitoring & Debugging - Cookbook Example 07\n",
        "\n",
        "This notebook demonstrates comprehensive monitoring, debugging, and observability techniques for WebSearcher agents in production environments.\n",
        "\n",
        "## üéØ What You'll Learn\n",
        "\n",
        "- Real-time monitoring and alerting\n",
        "- Performance metrics and dashboards\n",
        "- Debug logging and tracing\n",
        "- Health checks and system status\n",
        "- Error analysis and troubleshooting\n",
        "- Production deployment patterns\n",
        "- System observability best practices\n",
        "\n",
        "## üìä Monitoring Benefits\n",
        "\n",
        "1. **Visibility**: Complete insight into system behavior\n",
        "2. **Reliability**: Early detection of issues and degradation\n",
        "3. **Performance**: Optimization based on real usage patterns\n",
        "4. **Debugging**: Rapid troubleshooting and root cause analysis\n",
        "5. **Business Intelligence**: Usage analytics and cost optimization\n",
        "\n",
        "Let's build production-ready monitoring for research systems! üöÄ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup for monitoring and debugging\n",
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath('../../'))\n",
        "\n",
        "# Initialize prompt system\n",
        "import apps.research_prioritization.prompts.prompt_registry\n",
        "from agents import WebSearcher\n",
        "\n",
        "# Monitoring and debugging imports\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "import traceback\n",
        "import psutil\n",
        "import threading\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from typing import Dict, List, Any, Optional, Callable\n",
        "from datetime import datetime, timedelta\n",
        "from collections import defaultdict, deque\n",
        "from enum import Enum\n",
        "\n",
        "# Enhanced logging configuration\n",
        "logging.basicConfig(\n",
        "    level=logging.DEBUG,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s',\n",
        "    handlers=[\n",
        "        logging.StreamHandler(),\n",
        "        logging.FileHandler('websearcher_debug.log')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Specialized loggers\n",
        "monitor_logger = logging.getLogger('monitor')\n",
        "performance_logger = logging.getLogger('performance')\n",
        "error_logger = logging.getLogger('error')\n",
        "\n",
        "# Configuration\n",
        "MONITORING_CONFIG = {\n",
        "    \"reasoning\": {\"effort\": \"medium\"},\n",
        "    \"max_output_tokens\": 3000\n",
        "}\n",
        "\n",
        "print(\"üîç Monitoring & Debugging System Ready!\")\n",
        "print(f\"üíª Configuration: {MONITORING_CONFIG}\")\n",
        "print(f\"üìä Enhanced logging configured with file output\")\n",
        "print(f\"üöÄ Ready for production monitoring\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive monitoring and observability framework\n",
        "\n",
        "class MetricType(Enum):\n",
        "    \"\"\"Types of metrics to track\"\"\"\n",
        "    COUNTER = \"counter\"\n",
        "    GAUGE = \"gauge\" \n",
        "    HISTOGRAM = \"histogram\"\n",
        "    TIMER = \"timer\"\n",
        "\n",
        "class AlertLevel(Enum):\n",
        "    \"\"\"Alert severity levels\"\"\"\n",
        "    INFO = \"info\"\n",
        "    WARNING = \"warning\"\n",
        "    ERROR = \"error\"\n",
        "    CRITICAL = \"critical\"\n",
        "\n",
        "@dataclass\n",
        "class Metric:\n",
        "    \"\"\"Individual metric data point\"\"\"\n",
        "    name: str\n",
        "    value: float\n",
        "    metric_type: MetricType\n",
        "    timestamp: datetime = field(default_factory=datetime.now)\n",
        "    labels: Dict[str, str] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class Alert:\n",
        "    \"\"\"System alert\"\"\"\n",
        "    level: AlertLevel\n",
        "    component: str\n",
        "    message: str\n",
        "    timestamp: datetime = field(default_factory=datetime.now)\n",
        "    context: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class HealthCheck:\n",
        "    \"\"\"Health check result\"\"\"\n",
        "    component: str\n",
        "    status: str  # healthy, degraded, unhealthy\n",
        "    response_time: float\n",
        "    timestamp: datetime = field(default_factory=datetime.now)\n",
        "    details: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "class SystemMonitor:\n",
        "    \"\"\"Comprehensive system monitoring and observability\"\"\"\n",
        "    \n",
        "    def __init__(self, retention_hours: int = 24):\n",
        "        self.retention_hours = retention_hours\n",
        "        self.metrics: Dict[str, deque] = defaultdict(lambda: deque(maxlen=10000))\n",
        "        self.alerts: deque = deque(maxlen=1000)\n",
        "        self.health_checks: Dict[str, HealthCheck] = {}\n",
        "        self.alert_rules: List[Callable] = []\n",
        "        self.start_time = datetime.now()\n",
        "        \n",
        "        # System resource tracking\n",
        "        self.system_metrics_thread = None\n",
        "        self.monitoring_active = False\n",
        "        \n",
        "    def record_metric(self, name: str, value: float, metric_type: MetricType, labels: Dict[str, str] = None):\n",
        "        \"\"\"Record a metric data point\"\"\"\n",
        "        metric = Metric(\n",
        "            name=name,\n",
        "            value=value,\n",
        "            metric_type=metric_type,\n",
        "            labels=labels or {}\n",
        "        )\n",
        "        self.metrics[name].append(metric)\n",
        "        \n",
        "        # Clean old metrics\n",
        "        self._cleanup_old_metrics(name)\n",
        "        \n",
        "        # Check alert rules\n",
        "        self._check_alert_rules(metric)\n",
        "        \n",
        "        monitor_logger.debug(f\\\"Recorded metric: {name}={value} ({metric_type.value})\\\")\\n    \\n    def record_alert(self, level: AlertLevel, component: str, message: str, context: Dict[str, Any] = None):\\n        \\\"\\\"\\\"Record a system alert\\\"\\\"\\\"\\n        alert = Alert(\\n            level=level,\\n            component=component,\\n            message=message,\\n            context=context or {}\\n        )\\n        self.alerts.append(alert)\\n        \\n        # Log alert\\n        log_func = {\\n            AlertLevel.INFO: monitor_logger.info,\\n            AlertLevel.WARNING: monitor_logger.warning,\\n            AlertLevel.ERROR: error_logger.error,\\n            AlertLevel.CRITICAL: error_logger.critical\\n        }[level]\\n        \\n        log_func(f\\\"ALERT [{level.value.upper()}] {component}: {message}\\\")\\n    \\n    def update_health_check(self, component: str, status: str, response_time: float, details: Dict[str, Any] = None):\\n        \\\"\\\"\\\"Update component health status\\\"\\\"\\\"\\n        health_check = HealthCheck(\\n            component=component,\\n            status=status,\\n            response_time=response_time,\\n            details=details or {}\\n        )\\n        self.health_checks[component] = health_check\\n        \\n        monitor_logger.info(f\\\"Health check: {component} = {status} ({response_time:.3f}s)\\\")\\n        \\n        # Generate alerts for unhealthy components\\n        if status == \\\"unhealthy\\\":\\n            self.record_alert(AlertLevel.ERROR, component, f\\\"Component {component} is unhealthy\\\", \\n                            {\\\"response_time\\\": response_time, \\\"details\\\": details})\\n        elif status == \\\"degraded\\\":\\n            self.record_alert(AlertLevel.WARNING, component, f\\\"Component {component} is degraded\\\",\\n                            {\\\"response_time\\\": response_time, \\\"details\\\": details})\\n    \\n    def add_alert_rule(self, rule: Callable[[Metric], Optional[Alert]]):\\n        \\\"\\\"\\\"Add custom alert rule\\\"\\\"\\\"\\n        self.alert_rules.append(rule)\\n    \\n    def start_system_monitoring(self):\\n        \\\"\\\"\\\"Start background system resource monitoring\\\"\\\"\\\"\\n        if self.monitoring_active:\\n            return\\n            \\n        self.monitoring_active = True\\n        self.system_metrics_thread = threading.Thread(target=self._collect_system_metrics, daemon=True)\\n        self.system_metrics_thread.start()\\n        monitor_logger.info(\\\"Started system resource monitoring\\\")\\n    \\n    def stop_system_monitoring(self):\\n        \\\"\\\"\\\"Stop background monitoring\\\"\\\"\\\"\\n        self.monitoring_active = False\\n        if self.system_metrics_thread:\\n            self.system_metrics_thread.join(timeout=5)\\n        monitor_logger.info(\\\"Stopped system resource monitoring\\\")\\n    \\n    def _collect_system_metrics(self):\\n        \\\"\\\"\\\"Background thread to collect system metrics\\\"\\\"\\\"\\n        while self.monitoring_active:\\n            try:\\n                # CPU usage\\n                cpu_percent = psutil.cpu_percent(interval=1)\\n                self.record_metric(\\\"system_cpu_percent\\\", cpu_percent, MetricType.GAUGE)\\n                \\n                # Memory usage\\n                memory = psutil.virtual_memory()\\n                self.record_metric(\\\"system_memory_percent\\\", memory.percent, MetricType.GAUGE)\\n                self.record_metric(\\\"system_memory_available_mb\\\", memory.available / 1024 / 1024, MetricType.GAUGE)\\n                \\n                # Disk usage\\n                disk = psutil.disk_usage('/')\\n                self.record_metric(\\\"system_disk_percent\\\", (disk.used / disk.total) * 100, MetricType.GAUGE)\\n                \\n                time.sleep(10)  # Collect every 10 seconds\\n                \\n            except Exception as e:\\n                error_logger.error(f\\\"Error collecting system metrics: {e}\\\")\\n                time.sleep(30)  # Wait longer on error\\n    \\n    def _cleanup_old_metrics(self, metric_name: str):\\n        \\\"\\\"\\\"Remove metrics older than retention period\\\"\\\"\\\"\\n        cutoff_time = datetime.now() - timedelta(hours=self.retention_hours)\\n        metrics_queue = self.metrics[metric_name]\\n        \\n        while metrics_queue and metrics_queue[0].timestamp < cutoff_time:\\n            metrics_queue.popleft()\\n    \\n    def _check_alert_rules(self, metric: Metric):\\n        \\\"\\\"\\\"Check metric against alert rules\\\"\\\"\\\"\\n        for rule in self.alert_rules:\\n            try:\\n                alert = rule(metric)\\n                if alert:\\n                    self.alerts.append(alert)\\n            except Exception as e:\\n                error_logger.error(f\\\"Alert rule failed: {e}\\\")\\n    \\n    def get_dashboard_data(self) -> Dict[str, Any]:\\n        \\\"\\\"\\\"Get comprehensive dashboard data\\\"\\\"\\\"\\n        now = datetime.now()\\n        uptime = now - self.start_time\\n        \\n        # Recent metrics summary\\n        recent_metrics = {}\\n        for name, metrics_queue in self.metrics.items():\\n            if metrics_queue:\\n                latest = metrics_queue[-1]\\n                recent_metrics[name] = {\\n                    \\\"value\\\": latest.value,\\n                    \\\"timestamp\\\": latest.timestamp.isoformat(),\\n                    \\\"type\\\": latest.metric_type.value\\n                }\\n        \\n        # Recent alerts\\n        recent_alerts = [\\n            {\\n                \\\"level\\\": alert.level.value,\\n                \\\"component\\\": alert.component,\\n                \\\"message\\\": alert.message,\\n                \\\"timestamp\\\": alert.timestamp.isoformat()\\n            }\\n            for alert in list(self.alerts)[-10:]  # Last 10 alerts\\n        ]\\n        \\n        # Health status summary\\n        health_summary = {\\n            component: {\\n                \\\"status\\\": check.status,\\n                \\\"response_time\\\": check.response_time,\\n                \\\"timestamp\\\": check.timestamp.isoformat()\\n            }\\n            for component, check in self.health_checks.items()\\n        }\\n        \\n        return {\\n            \\\"timestamp\\\": now.isoformat(),\\n            \\\"uptime_seconds\\\": uptime.total_seconds(),\\n            \\\"metrics\\\": recent_metrics,\\n            \\\"alerts\\\": recent_alerts,\\n            \\\"health_checks\\\": health_summary,\\n            \\\"total_metrics_collected\\\": sum(len(q) for q in self.metrics.values()),\\n            \\\"total_alerts\\\": len(self.alerts)\\n        }\\n\\nclass MonitoredWebSearcher:\\n    \\\"\\\"\\\"WebSearcher with comprehensive monitoring integration\\\"\\\"\\\"\\n    \\n    def __init__(self, prompt_alias: str, client_config: dict, monitor: SystemMonitor):\\n        self.prompt_alias = prompt_alias\\n        self.client_config = client_config\\n        self.searcher = WebSearcher(prompt_alias, client_config)\\n        self.monitor = monitor\\n        self.request_count = 0\\n        \\n    def search_with_monitoring(self, template_kwargs: dict) -> Any:\\n        \\\"\\\"\\\"Execute search with comprehensive monitoring\\\"\\\"\\\"\\n        request_id = f\\\"{self.prompt_alias}_{self.request_count}\\\"\\n        self.request_count += 1\\n        \\n        start_time = time.time()\\n        disease_name = template_kwargs.get('disease_name', 'Unknown')\\n        \\n        # Record request start\\n        self.monitor.record_metric(\\n            f\\\"requests_total\\\", \\n            1, \\n            MetricType.COUNTER, \\n            {\\\"prompt_alias\\\": self.prompt_alias, \\\"disease\\\": disease_name}\\n        )\\n        \\n        monitor_logger.info(f\\\"Starting search request {request_id} for {disease_name}\\\")\\n        \\n        try:\\n            # Execute search\\n            result = self.searcher.search(template_kwargs)\\n            \\n            # Record success metrics\\n            response_time = time.time() - start_time\\n            self.monitor.record_metric(\\n                f\\\"request_duration_seconds\\\",\\n                response_time,\\n                MetricType.TIMER,\\n                {\\\"prompt_alias\\\": self.prompt_alias, \\\"status\\\": \\\"success\\\"}\\n            )\\n            \\n            self.monitor.record_metric(\\n                f\\\"requests_successful_total\\\",\\n                1,\\n                MetricType.COUNTER,\\n                {\\\"prompt_alias\\\": self.prompt_alias}\\n            )\\n            \\n            # Record result-specific metrics\\n            if hasattr(result, 'score'):\\n                self.monitor.record_metric(\\n                    f\\\"result_score\\\",\\n                    float(result.score),\\n                    MetricType.GAUGE,\\n                    {\\\"prompt_alias\\\": self.prompt_alias, \\\"disease\\\": disease_name}\\n                )\\n            \\n            performance_logger.info(\\n                f\\\"Request {request_id} completed successfully in {response_time:.3f}s\\\"\\n            )\\n            \\n            # Update health check\\n            self.monitor.update_health_check(\\n                self.prompt_alias,\\n                \\\"healthy\\\" if response_time < 5.0 else \\\"degraded\\\",\\n                response_time,\\n                {\\\"last_request_id\\\": request_id, \\\"result_type\\\": type(result).__name__}\\n            )\\n            \\n            return result\\n            \\n        except Exception as e:\\n            # Record error metrics\\n            response_time = time.time() - start_time\\n            \\n            self.monitor.record_metric(\\n                f\\\"requests_failed_total\\\",\\n                1,\\n                MetricType.COUNTER,\\n                {\\\"prompt_alias\\\": self.prompt_alias, \\\"error_type\\\": type(e).__name__}\\n            )\\n            \\n            self.monitor.record_metric(\\n                f\\\"request_duration_seconds\\\",\\n                response_time,\\n                MetricType.TIMER,\\n                {\\\"prompt_alias\\\": self.prompt_alias, \\\"status\\\": \\\"error\\\"}\\n            )\\n            \\n            # Record alert\\n            self.monitor.record_alert(\\n                AlertLevel.ERROR,\\n                self.prompt_alias,\\n                f\\\"Search request failed: {str(e)}\\\",\\n                {\\n                    \\\"request_id\\\": request_id,\\n                    \\\"disease_name\\\": disease_name,\\n                    \\\"error_type\\\": type(e).__name__,\\n                    \\\"traceback\\\": traceback.format_exc()\\n                }\\n            )\\n            \\n            # Update health check\\n            self.monitor.update_health_check(\\n                self.prompt_alias,\\n                \\\"unhealthy\\\",\\n                response_time,\\n                {\\\"last_error\\\": str(e), \\\"request_id\\\": request_id}\\n            )\\n            \\n            error_logger.error(\\n                f\\\"Request {request_id} failed after {response_time:.3f}s: {e}\\\",\\n                exc_info=True\\n            )\\n            \\n            raise  # Re-raise the exception\\n\\n# Initialize monitoring system\\nsystem_monitor = SystemMonitor(retention_hours=24)\\n\\n# Add custom alert rules\\ndef high_error_rate_rule(metric: Metric) -> Optional[Alert]:\\n    \\\"\\\"\\\"Alert on high error rates\\\"\\\"\\\"\\n    if metric.name == \\\"requests_failed_total\\\" and metric.value > 5:\\n        return Alert(\\n            level=AlertLevel.WARNING,\\n            component=\\\"error_rate\\\",\\n            message=f\\\"High error rate detected: {metric.value} failures\\\",\\n            context={\\\"metric\\\": asdict(metric)}\\n        )\\n    return None\\n\\ndef slow_response_rule(metric: Metric) -> Optional[Alert]:\\n    \\\"\\\"\\\"Alert on slow responses\\\"\\\"\\\"\\n    if metric.name == \\\"request_duration_seconds\\\" and metric.value > 10.0:\\n        return Alert(\\n            level=AlertLevel.WARNING,\\n            component=\\\"performance\\\",\\n            message=f\\\"Slow response detected: {metric.value:.2f}s\\\",\\n            context={\\\"metric\\\": asdict(metric)}\\n        )\\n    return None\\n\\nsystem_monitor.add_alert_rule(high_error_rate_rule)\\nsystem_monitor.add_alert_rule(slow_response_rule)\\n\\n# Initialize monitored searchers\\nmonitored_socio = MonitoredWebSearcher(\\\"socioeconomic_v2\\\", MONITORING_CONFIG, system_monitor)\\nmonitored_groups = MonitoredWebSearcher(\\\"groups_v1\\\", MONITORING_CONFIG, system_monitor)\\n\\n# Start system monitoring\\nsystem_monitor.start_system_monitoring()\\n\\nprint(\\\"üîç Comprehensive monitoring system initialized!\\\")\\nprint(\\\"‚úÖ Features: Metrics collection, Alerting, Health checks, Performance tracking\\\")\\nprint(\\\"üìä System resource monitoring started\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## üìä Live Monitoring Dashboard\\n\",\n",
        "    \"\\n\",\n",
        "    \"Let's demonstrate the monitoring system with real requests and dashboard views.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Execute monitored requests to generate metrics\\n\",\n",
        "    \"print(\\\"üß™ EXECUTING MONITORED REQUESTS\\\")\\n\",\n",
        "    \"print(\\\"=\\\" * 35)\\n\",\n",
        "    \"\\n\",\n",
        "    \"test_diseases = [\\n\",\n",
        "    \"    (\\\"905\\\", \\\"Wilson disease\\\"),\\n\",\n",
        "    \"    (\\\"399\\\", \\\"Huntington disease\\\"),\\n\",\n",
        "    \"    (\\\"98\\\", \\\"Alpers syndrome\\\")\\n\",\n",
        "    \"]\\n\",\n",
        "    \"\\n\",\n",
        "    \"results = []\\n\",\n",
        "    \"\\n\",\n",
        "    \"for orphacode, disease_name in test_diseases:\\n\",\n",
        "    \"    template_data = {\\\"orphacode\\\": orphacode, \\\"disease_name\\\": disease_name}\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(f\\\"\\\\nüî¨ Analyzing {disease_name}...\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    try:\\n\",\n",
        "    \"        # Socioeconomic analysis\\n\",\n",
        "    \"        socio_result = monitored_socio.search_with_monitoring(template_data)\\n\",\n",
        "    \"        print(f\\\"   üìä Socioeconomic: Score {socio_result.score if hasattr(socio_result, 'score') else 'N/A'}\\\")\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        # Groups analysis\\n\",\n",
        "    \"        groups_result = monitored_groups.search_with_monitoring(template_data)\\n\",\n",
        "    \"        group_count = len(groups_result.groups) if hasattr(groups_result, 'groups') and groups_result.groups else 0\\n\",\n",
        "    \"        print(f\\\"   üë• Groups: {group_count} found\\\")\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        results.append((disease_name, socio_result, groups_result))\\n\",\n",
        "    \"        \\n\",\n",
        "    \"    except Exception as e:\\n\",\n",
        "    \"        print(f\\\"   ‚ùå Error: {str(e)[:50]}...\\\")\\n\",\n",
        "    \"        results.append((disease_name, None, None))\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Small delay to see metrics accumulate\\n\",\n",
        "    \"    time.sleep(1)\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(f\\\"\\\\n‚úÖ Completed {len(results)} disease analyses\\\")\\n\",\n",
        "    \"print(\\\"üìä Metrics and alerts have been collected\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Display comprehensive monitoring dashboard\\n\",\n",
        "    \"dashboard_data = system_monitor.get_dashboard_data()\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"üìä MONITORING DASHBOARD\\\")\\n\",\n",
        "    \"print(\\\"=\\\" * 25)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# System overview\\n\",\n",
        "    \"uptime_hours = dashboard_data['uptime_seconds'] / 3600\\n\",\n",
        "    \"print(f\\\"‚è±Ô∏è  System Uptime: {uptime_hours:.2f} hours\\\")\\n\",\n",
        "    \"print(f\\\"üìà Total Metrics: {dashboard_data['total_metrics_collected']}\\\")\\n\",\n",
        "    \"print(f\\\"üö® Total Alerts: {dashboard_data['total_alerts']}\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Health status\\n\",\n",
        "    \"print(f\\\"\\\\nüíö COMPONENT HEALTH STATUS\\\")\\n\",\n",
        "    \"print(\\\"-\\\" * 30)\\n\",\n",
        "    \"if dashboard_data['health_checks']:\\n\",\n",
        "    \"    for component, health in dashboard_data['health_checks'].items():\\n\",\n",
        "    \"        status_emoji = {\\n\",\n",
        "    \"            \\\"healthy\\\": \\\"‚úÖ\\\",\\n\",\n",
        "    \"            \\\"degraded\\\": \\\"‚ö†Ô∏è\\\",\\n\",\n",
        "    \"            \\\"unhealthy\\\": \\\"‚ùå\\\"\\n\",\n",
        "    \"        }.get(health['status'], \\\"‚ùì\\\")\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        print(f\\\"{status_emoji} {component}: {health['status']} ({health['response_time']:.3f}s)\\\")\\nelse:\\n    print(\\\"No health checks available\\\")\\n\\n# Recent metrics\\nprint(f\\\"\\\\nüìä RECENT METRICS\\\")\\nprint(\\\"-\\\" * 20)\\nif dashboard_data['metrics']:\\n    for name, metric in dashboard_data['metrics'].items():\\n        if 'system_' not in name:  # Focus on application metrics\\n            print(f\\\"   {name}: {metric['value']} ({metric['type']})\\\")\\nelse:\\n    print(\\\"No recent metrics available\\\")\\n\\n# System resources\\nprint(f\\\"\\\\nüñ•Ô∏è  SYSTEM RESOURCES\\\")\\nprint(\\\"-\\\" * 20)\\nfor name, metric in dashboard_data['metrics'].items():\\n    if name.startswith('system_'):\\n        metric_name = name.replace('system_', '').replace('_', ' ').title()\\n        unit = \\\"%\\\" if \\\"percent\\\" in name else \\\"MB\\\" if \\\"mb\\\" in name else \\\"\\\"\\n        print(f\\\"   {metric_name}: {metric['value']:.1f}{unit}\\\")\\n\\n# Recent alerts\\nprint(f\\\"\\\\nüö® RECENT ALERTS\\\")\\nprint(\\\"-\\\" * 15)\\nif dashboard_data['alerts']:\\n    for alert in dashboard_data['alerts'][-5:]:  # Last 5 alerts\\n        level_emoji = {\\n            \\\"info\\\": \\\"‚ÑπÔ∏è\\\",\\n            \\\"warning\\\": \\\"‚ö†Ô∏è\\\",\\n            \\\"error\\\": \\\"‚ùå\\\",\\n            \\\"critical\\\": \\\"üî•\\\"\\n        }.get(alert['level'], \\\"‚ùì\\\")\\n        \\n        timestamp = datetime.fromisoformat(alert['timestamp']).strftime(\\\"%H:%M:%S\\\")\\n        print(f\\\"   {level_emoji} [{timestamp}] {alert['component']}: {alert['message'][:60]}...\\\")\\nelse:\\n    print(\\\"   No recent alerts\\\")\\n\\n# Performance summary\\nrequest_metrics = {\\n    name: metric for name, metric in dashboard_data['metrics'].items() \\n    if 'request' in name or 'duration' in name\\n}\\n\\nif request_metrics:\\n    print(f\\\"\\\\n‚ö° PERFORMANCE SUMMARY\\\")\\n    print(\\\"-\\\" * 22)\\n    for name, metric in request_metrics.items():\\n        print(f\\\"   {name}: {metric['value']}\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## üîß Debugging and Troubleshooting\\n\",\n",
        "    \"\\n\",\n",
        "    \"Let's demonstrate debugging capabilities with simulated issues.\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Debugging utilities and troubleshooting tools\\n\",\n",
        "    \"\\n\",\n",
        "    \"def generate_debug_report(monitor: SystemMonitor) -> Dict[str, Any]:\\n\",\n",
        "    \"    \\\"\\\"\\\"Generate comprehensive debug report\\\"\\\"\\\"\\n    \\n\",\n",
        "    \"    dashboard = monitor.get_dashboard_data()\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Error analysis\\n\",\n",
        "    \"    error_alerts = [\\n\",\n",
        "    \"        alert for alert in monitor.alerts \\n\",\n",
        "    \"        if alert.level in [AlertLevel.ERROR, AlertLevel.CRITICAL]\\n\",\n",
        "    \"    ]\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Performance analysis\\n\",\n",
        "    \"    slow_requests = []\\n\",\n",
        "    \"    for metric_name, metrics_queue in monitor.metrics.items():\\n\",\n",
        "    \"        if \\\"duration\\\" in metric_name:\\n\",\n",
        "    \"            for metric in metrics_queue:\\n\",\n",
        "    \"                if metric.value > 5.0:  # Requests slower than 5s\\n\",\n",
        "    \"                    slow_requests.append({\\n\",\n",
        "    \"                        \\\"metric\\\": metric_name,\\n\",\n",
        "    \"                        \\\"duration\\\": metric.value,\\n\",\n",
        "    \"                        \\\"timestamp\\\": metric.timestamp.isoformat(),\\n\",\n",
        "    \"                        \\\"labels\\\": metric.labels\\n\",\n",
        "    \"                    })\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Component health analysis\\n\",\n",
        "    \"    unhealthy_components = {\\n\",\n",
        "    \"        comp: health for comp, health in monitor.health_checks.items()\\n\",\n",
        "    \"        if health.status in [\\\"degraded\\\", \\\"unhealthy\\\"]\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    return {\\n\",\n",
        "    \"        \\\"generated_at\\\": datetime.now().isoformat(),\\n\",\n",
        "    \"        \\\"system_overview\\\": dashboard,\\n\",\n",
        "    \"        \\\"error_analysis\\\": {\\n\",\n",
        "    \"            \\\"total_errors\\\": len(error_alerts),\\n\",\n",
        "    \"            \\\"recent_errors\\\": [asdict(alert) for alert in error_alerts[-10:]]\\n\",\n",
        "    \"        },\\n\",\n",
        "    \"        \\\"performance_analysis\\\": {\\n\",\n",
        "    \"            \\\"slow_requests_count\\\": len(slow_requests),\\n\",\n",
        "    \"            \\\"slow_requests\\\": slow_requests[-5:]  # Last 5 slow requests\\n\",\n",
        "    \"        },\\n\",\n",
        "    \"        \\\"health_analysis\\\": {\\n\",\n",
        "    \"            \\\"unhealthy_components_count\\\": len(unhealthy_components),\\n\",\n",
        "    \"            \\\"unhealthy_components\\\": {\\n\",\n",
        "    \"                comp: asdict(health) for comp, health in unhealthy_components.items()\\n\",\n",
        "    \"            }\\n\",\n",
        "    \"        }\\n\",\n",
        "    \"    }\\n\",\n",
        "    \"\\n\",\n",
        "    \"def simulate_error_scenario():\\n\",\n",
        "    \"    \\\"\\\"\\\"Simulate an error scenario for debugging demonstration\\\"\\\"\\\"\\n\",\n",
        "    \"    print(\\\"üß™ SIMULATING ERROR SCENARIO\\\")\\n\",\n",
        "    \"    print(\\\"-\\\" * 30)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Simulate some failures\\n\",\n",
        "    \"    try:\\n\",\n",
        "    \"        # This will fail due to invalid orphacode\\n\",\n",
        "    \"        invalid_data = {\\\"orphacode\\\": \\\"INVALID\\\", \\\"disease_name\\\": \\\"Test Disease\\\"}\\n\",\n",
        "    \"        monitored_socio.search_with_monitoring(invalid_data)\\n\",\n",
        "    \"    except Exception as e:\\n\",\n",
        "    \"        print(f\\\"‚úÖ Expected error captured: {type(e).__name__}\\\")\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    # Record some manual alerts for demonstration\\n\",\n",
        "    \"    system_monitor.record_alert(\\n\",\n",
        "    \"        AlertLevel.WARNING,\\n\",\n",
        "    \"        \\\"test_component\\\",\\n\",\n",
        "    \"        \\\"Simulated degraded performance\\\",\\n\",\n",
        "    \"        {\\\"test_scenario\\\": True}\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    system_monitor.record_alert(\\n\",\n",
        "    \"        AlertLevel.ERROR,\\n\",\n",
        "    \"        \\\"data_validation\\\",\\n\",\n",
        "    \"        \\\"Invalid input data detected\\\",\\n\",\n",
        "    \"        {\\\"invalid_orphacode\\\": \\\"INVALID\\\"}\\n\",\n",
        "    \"    )\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    print(\\\"üö® Error scenario simulation complete\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Run error simulation\\n\",\n",
        "    \"simulate_error_scenario()\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Generate debug report\\n\",\n",
        "    \"print(\\\"\\\\nüîç GENERATING DEBUG REPORT\\\")\\n\",\n",
        "    \"print(\\\"=\\\" * 30)\\n\",\n",
        "    \"\\n\",\n",
        "    \"debug_report = generate_debug_report(system_monitor)\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(f\\\"üìä Debug Report Generated at: {debug_report['generated_at']}\\\")\\nprint(f\\\"\\\\n‚ùå ERROR ANALYSIS:\\\")\\nprint(f\\\"   Total errors: {debug_report['error_analysis']['total_errors']}\\\")\\nif debug_report['error_analysis']['recent_errors']:\\n    print(f\\\"   Recent errors:\\\")\\n    for error in debug_report['error_analysis']['recent_errors'][-3:]:\\n        print(f\\\"     ‚Ä¢ [{error['level']}] {error['component']}: {error['message'][:50]}...\\\")\\n\\nprint(f\\\"\\\\n‚ö° PERFORMANCE ANALYSIS:\\\")\\nprint(f\\\"   Slow requests: {debug_report['performance_analysis']['slow_requests_count']}\\\")\\nif debug_report['performance_analysis']['slow_requests']:\\n    print(f\\\"   Recent slow requests:\\\")\\n    for req in debug_report['performance_analysis']['slow_requests']:\\n        print(f\\\"     ‚Ä¢ {req['metric']}: {req['duration']:.2f}s\\\")\\n\\nprint(f\\\"\\\\nüíö HEALTH ANALYSIS:\\\")\\nprint(f\\\"   Unhealthy components: {debug_report['health_analysis']['unhealthy_components_count']}\\\")\\nif debug_report['health_analysis']['unhealthy_components']:\\n    for comp, health in debug_report['health_analysis']['unhealthy_components'].items():\\n        print(f\\\"     ‚Ä¢ {comp}: {health['status']} ({health['response_time']:.3f}s)\\\")\\n\\n# Save debug report to file\\nwith open('debug_report.json', 'w') as f:\\n    json.dump(debug_report, f, indent=2, default=str)\\nprint(f\\\"\\\\nüíæ Debug report saved to 'debug_report.json'\\\")\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"metadata\": {},\n",
        "   \"source\": [\n",
        "    \"## üìö Key Learnings & Best Practices\\n\",\n",
        "    \"\\n\",\n",
        "    \"### ‚úÖ What We Accomplished\\n\",\n",
        "    \"\\n\",\n",
        "    \"1. **Comprehensive Monitoring**: Metrics, alerts, and health checks\\n\",\n",
        "    \"2. **Real-time Observability**: Live dashboard with system insights\\n\",\n",
        "    \"3. **Error Tracking**: Detailed error analysis and troubleshooting\\n\",\n",
        "    \"4. **Performance Monitoring**: Response times and throughput tracking\\n\",\n",
        "    \"5. **System Health**: Resource usage and component status monitoring\\n\",\n",
        "    \"6. **Debug Reporting**: Automated troubleshooting and analysis tools\\n\",\n",
        "    \"\\n\",\n",
        "    \"### üéØ Production Monitoring Essentials\\n\",\n",
        "    \"\\n\",\n",
        "    \"- **Four Golden Signals**: Latency, traffic, errors, and saturation\\n\",\n",
        "    \"- **Proactive Alerting**: Catch issues before they impact users\\n\",\n",
        "    \"- **Health Checks**: Regular component status verification\\n\",\n",
        "    \"- **Debug Tools**: Rapid troubleshooting capabilities\\n\",\n",
        "    \"- **Historical Data**: Trend analysis and capacity planning\\n\",\n",
        "    \"\\n\",\n",
        "    \"### üìä Monitoring Stack Components\\n\",\n",
        "    \"\\n\",\n",
        "    \"- **Metrics Collection**: Custom metrics with labels and metadata\\n\",\n",
        "    \"- **Alert Management**: Severity-based alerting with context\\n\",\n",
        "    \"- **Health Monitoring**: Component status and response time tracking\\n\",\n",
        "    \"- **System Resources**: CPU, memory, and disk usage monitoring\\n\",\n",
        "    \"- **Performance Analytics**: Request duration and throughput analysis\\n\",\n",
        "    \"\\n\",\n",
        "    \"### üöÄ Next Steps for Production\\n\",\n",
        "    \"\\n\",\n",
        "    \"- **External Monitoring**: Integrate with Prometheus, Grafana, or DataDog\\n\",\n",
        "    \"- **Log Aggregation**: Centralized logging with ELK stack or similar\\n\",\n",
        "    \"- **Distributed Tracing**: Request tracing across microservices\\n\",\n",
        "    \"- **Automated Remediation**: Self-healing systems and auto-scaling\\n\",\n",
        "    \"- **Business Metrics**: Track research impact and cost optimization\\n\",\n",
        "    \"\\n\",\n",
        "    \"### üõ°Ô∏è Security and Compliance\\n\",\n",
        "    \"\\n\",\n",
        "    \"- **Audit Logging**: Complete request and response logging\\n\",\n",
        "    \"- **Privacy Protection**: Ensure no sensitive data in logs\\n\",\n",
        "    \"- **Access Control**: Secure monitoring dashboard access\\n\",\n",
        "    \"- **Compliance Reporting**: Automated compliance and audit reports\\n\",\n",
        "    \"\\n\",\n",
        "    \"The monitoring and debugging framework ensures production-ready observability! üéä\"\n",
        "   ]\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"execution_count\": null,\n",
        "   \"metadata\": {},\n",
        "   \"outputs\": [],\n",
        "   \"source\": [\n",
        "    \"# Cleanup - stop monitoring\\n\",\n",
        "    \"print(\\\"üßπ CLEANUP\\\")\\n\",\n",
        "    \"print(\\\"=\\\" * 10)\\n\",\n",
        "    \"\\n\",\n",
        "    \"system_monitor.stop_system_monitoring()\\n\",\n",
        "    \"print(\\\"‚úÖ System monitoring stopped\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"# Final dashboard snapshot\\n\",\n",
        "    \"final_dashboard = system_monitor.get_dashboard_data()\\n\",\n",
        "    \"print(f\\\"üìä Final metrics count: {final_dashboard['total_metrics_collected']}\\\")\\n\",\n",
        "    \"print(f\\\"üö® Final alerts count: {final_dashboard['total_alerts']}\\\")\\n\",\n",
        "    \"print(f\\\"‚è±Ô∏è  Total uptime: {final_dashboard['uptime_seconds']:.1f} seconds\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"\\\\nüéä Monitoring demonstration complete!\\\")\\n\",\n",
        "    \"print(\\\"üìñ Check 'websearcher_debug.log' and 'debug_report.json' for detailed logs\\\")\"\n",
        "   ]\n",
        "  }\n",
        " ],\n",
        " \"metadata\": {\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"language\": \"python\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"codemirror_mode\": {\n",
        "    \"name\": \"ipython\",\n",
        "    \"version\": 3\n",
        "   },\n",
        "   \"file_extension\": \".py\",\n",
        "   \"mimetype\": \"text/x-python\",\n",
        "   \"name\": \"python\",\n",
        "   \"nbconvert_exporter\": \"python\",\n",
        "   \"pygments_lexer\": \"ipython3\",\n",
        "   \"version\": \"3.8.0\"\n",
        "  }\n",
        " },\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 4\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
